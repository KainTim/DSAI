{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01cb1e74",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    border: 2px solid #4CAF50; \n",
    "    padding: 15px; \n",
    "    background-color: #f4f4f4; \n",
    "    border-radius: 10px; \n",
    "    align-items: center;\">\n",
    "\n",
    "<h1 style=\"margin: 0; color: #4CAF50;\">Neural Networks: Die Train Methode + Tipps und Tricks</h1>\n",
    "<h2 style=\"margin: 5px 0; color: #555;\">DSAI</h2>\n",
    "<h3 style=\"margin: 5px 0; color: #555;\">Jakob Eggl</h3>\n",
    "\n",
    "<div style=\"flex-shrink: 0;\">\n",
    "    <img src=\"https://www.htl-grieskirchen.at/wp/wp-content/uploads/2022/11/logo_bildschirm-1024x503.png\" alt=\"Logo\" style=\"width: 250px; height: auto;\"/>\n",
    "</div>\n",
    "<p1> © 2025/26 Jakob Eggl. Nutzung oder Verbreitung nur mit ausdrücklicher Genehmigung des Autors.</p1>\n",
    "</div>\n",
    "<div style=\"flex: 1;\">\n",
    "</div>   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2438fc",
   "metadata": {},
   "source": [
    "In diesem Notebook werden wir uns mit der **Trainingsmethode** befassen. Das bedeutet, dass wir uns ansehen werden, wie normalerweise eine Trainingsmethode aussieht.\n",
    "\n",
    "Dabei werden wir sowohl:\n",
    "* Notwendige Schritte besprechen, als auch\n",
    "* *Tipps und Tricks* besprechen, welche für den reinen Lernprozess nicht notwendig sind, jedoch uns das Leben wesentlich erleichtern können."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93c5568",
   "metadata": {},
   "source": [
    "## Wiederholung: Welche Punkte müssen wir abarbeiten?\n",
    "\n",
    "1. Wir definieren unsere Modellklasse und erstellen eine Instanz $f$. Unser Modell hat dabei die Parameter $w$ (genannt *Weights*).\n",
    "2. Wir haben unsere Daten in einem Dataset und einen zugehörigen Dataloader verfügbar. Dabei steht $X$ für die \"Input\"-Daten und $y$ das dazugehörige Label.\n",
    "3. Wir haben eine Loss-Funktion $L(\\hat{y},y)$ definiert.\n",
    "4. Wir haben einen Optimizer (zum Beispiel SGD) und eine Learning Rate $\\eta$ festgelegt.\n",
    "5. Wir schicken die Daten ($X$) durch das Modell und erhalten die Prediction $\\hat{y} = f(X)$.\n",
    "6. Wir vergleichen die echte Lösung $y$ mit unserer Prediction $\\hat{y}=f(X)$ indem wir den Loss $L(\\hat{y},y)$ berechnen.\n",
    "7. Wir berechnen die Ableitung der Lossfunktion $L$ bezüglich der Parameter $w$ und updaten diese bezüglich der Regel $w_t = w_{t-1} - \\eta \\nabla L(w_{t-1})$\n",
    "8. Wir wiederholen die Schritte 5, 6 und 7 mehrmals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2c0294",
   "metadata": {},
   "source": [
    "Versuchen wir nun, dies in Python (PyTorch) zu implementieren."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9436ccf",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a13287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c909676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('mps') if torch.backends.mps.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabf2ff4",
   "metadata": {},
   "source": [
    "Nehmen wir nun das `california_housing` Dataset, gespeichert unter `housing.csv`. Dieses wollen wir für Regression verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e34db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(\"..\", \"..\", \"_data\", \"housing.csv\")\n",
    "data = pd.read_csv(path, sep=',', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51ae055",
   "metadata": {},
   "source": [
    "(Hier müssten wir jetzt eigentlich noch eine genau Datenanalyse machen. Wir gehen aber jetzt davon aus, dass dies schon gemacht wurde und wir führen somit einfach die folgenden Schritt durch.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8acd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3efae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5128e391",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_colums = [\"mainroad\", \"guestroom\", \"basement\", \"hotwaterheating\", \"airconditioning\", \"prefarea\",\"furnishingstatus\"]\n",
    "\n",
    "for col in str_colums:\n",
    "    print(col,\":\",data[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2167eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_colums = [\"mainroad\", \"guestroom\", \"basement\", \"hotwaterheating\", \"airconditioning\", \"prefarea\"]\n",
    "\n",
    "for col in bin_colums:\n",
    "    data[col] = data[col].map({\"yes\":1,\"no\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37f682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "furnish_encoder = OrdinalEncoder(categories=[[\"unfurnished\",\"semi-furnished\",\"furnished\"]])\n",
    "\n",
    "data[\"furnishingstatus\"] = furnish_encoder.fit_transform(data[[\"furnishingstatus\"]])\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0d5e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "scale_cols = [\"area\"]\n",
    "\n",
    "data[scale_cols] = scaler.fit_transform(data[scale_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5148147",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31fc825",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['price'] /= 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cf8a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf149f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"price\", axis=1)\n",
    "y = data[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957ad9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(torch.tensor(X.values, dtype=torch.float32), torch.tensor(y.values, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6785b1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_ratio = 0.7\n",
    "test_set_ratio = 0.3\n",
    "\n",
    "train_length = int(round(train_set_ratio * len(dataset)))\n",
    "test_length = len(dataset) - train_length\n",
    "train_dataset, test_dataset = random_split(dataset, [train_length, test_length])\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92d4147",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRegressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleRegressor, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(12, 24),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(24, 12),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(12, 6),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(6, 1)\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c5c856",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleRegressor().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1491a515",
   "metadata": {},
   "source": [
    "Wir werden sehen, dass beim Optimizer die **Model-Parameter** übergeben werden. Dieser Schritt ist sehr wichtig.\n",
    "\n",
    "Wir sehen uns an dieser Stelle mal die Model-Parameter an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f97047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show number of model parameters and where they come from\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total model parameters: {total_params}\")\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Parameter: {name}, Shape: {param.shape}, Size: {param.numel()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163cb950",
   "metadata": {},
   "source": [
    "Nun zur eigentlichen **Trainingsmethode**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2957083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3) # or SGD for example\n",
    "\n",
    "n_epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163e1747",
   "metadata": {},
   "source": [
    "**Wichtig:** Hier müssen die Parameter vom Modell beim Optimizer übergeben werden. Diese werden dann im Laufe geupdated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bcf8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Starting training on device: {device}...\")\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    model.train()\n",
    "    train_losses_this_epoch = []\n",
    "\n",
    "    for train_input, train_label in train_loader:\n",
    "        train_input, train_label = train_input.to(device), train_label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(train_input)\n",
    "        loss = criterion(prediction, train_label)\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        train_losses_this_epoch.append(loss.item()) # .item() to get scalar value from tensor.\n",
    "    avg_train_loss = np.mean(train_losses_this_epoch)\n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    test_losses_this_epoch = []\n",
    "    with torch.no_grad():\n",
    "        for test_input, test_label in test_loader:\n",
    "            test_input, test_label = test_input.to(device), test_label.to(device)\n",
    "\n",
    "            test_prediction = model(test_input)\n",
    "            test_loss = criterion(test_prediction, test_label)\n",
    "            test_losses_this_epoch.append(test_loss.item())\n",
    "    avg_test_loss = np.mean(test_losses_this_epoch)\n",
    "    print(f\"Epoch {epoch}/{n_epochs} - Train Loss: {avg_train_loss:.4f} - Test Loss: {avg_test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde6ac63",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Der Testloss beträgt {avg_test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7e3a3a",
   "metadata": {},
   "source": [
    "Insbesondere sind folgende Punkte im Code **extrem** wichtig (sortiert der Reihe nach, wie sie in der Methode auftreten):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cf5077",
   "metadata": {},
   "source": [
    "* `model.train()`: Setzt das Modell in den Trainingsmodus und aktiviert dabei Effekte, welche wir im Training haben wollen und in der späteren Verwendung (=Inferenz) nicht. (Siehe später zum Beispiel **Dropout-Layer**)\n",
    "* `optimizer.zero_grad()`: Setzt alle Gradienten zurück. Grund: Wir wollen jede Iteration den Gradient neu berechnen und nicht die alten Gradients noch miteinbeziehen.\n",
    "* `loss = criterion(prediction, train_label)`: Berechnet den Loss, indem es die Prediction und das Label vergleicht.\n",
    "* `loss.backward()`: Berechnet die Gradienten bezüglich der Parameter (Weights) des Modells (werden vorher in der Initialisierung vom Optimizer übergeben).\n",
    "* `optimizer.step()`: Aktualisiert die Parameter bzgl. der gewählten **Update-Rule** (zum Beispiel (Stochastic)Gradient-Descent).\n",
    "* `model.eval()`: Gegenstück zu `model.train()`: Setzt also das Modell in den Evaluierungsmodus, dabei werden einige Effekte, welche wir im Training haben wollen und in der späteren Verwendung nicht, deaktiviert. (Auch hier: Siehe zum Beispiel **Dropout-Layer**)\n",
    "* `with torch.no_grad()`: Gibt der Autograd-Engine bescheid, dass keine Gradienten gespeichert/berechnet werden sollen. Dies resultiert in einem Geschwindigkeitsboost und einem geringeren Speicherverbrauch. Kann jedoch nur im Evaluierungsmodus verwendet werden. Theoretisch könnten wir somit für das Evaluieren mehr Daten gleichzeitig durch das Modell schicken (größere Batch-Size), nachdem wir weniger Speicher benötigen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eafb3d",
   "metadata": {},
   "source": [
    "**Wir wollen nochmal kurz die wichtigsten Parameter hier durchgehen:**\n",
    "\n",
    "* `n_epochs`: Anzahl der Durchläufe des *gesamten* Datasets. Normalerweise schon viel größer als 1. Zu große Anzahl kann zu Overfitting führen. **Lösung:** Early Stopping (siehe später)\n",
    "* `criterion`: Loss Funktion, welche wir verwenden wollen. Normalerweise Mean Squared Error (MSE) oder Cross Entropy Loss (CE)\n",
    "* `lr`: Learning Rate, welche vorgibt, wie groß die Schritte in die jeweilige Richtung des steilsten Abstiegs gemacht werden sollen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebf47ea",
   "metadata": {},
   "source": [
    "**Was ist jetzt noch suboptimal?**\n",
    "\n",
    "1) Wir verwenden das Testset zwischendurch zum Abfragen der Performance (das ist eigentlich genau genommen auch overfitting).\n",
    "2) Wir verwenden eine fixe Anzahl an Epochen. Dies kann bei zu kleiner oder zu großer Wahl zu under- bzw. overfitting führen. Außerdem verwenden wir dadurch nicht das Modell, welches zwingend am besten (beim Testset) ist.\n",
    "3) Wir lassen uns nicht recht viele Parameter zum Trainingsvorgang ausgeben."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f1462e",
   "metadata": {},
   "source": [
    "Diese Probleme werden wir jetzt Schritt für Schritt lösen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319bdf2b",
   "metadata": {},
   "source": [
    "### Lösung zu Problem 1 und 2 (Mehrfaches Verwenden vom Testset + kein Early Stopping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972fa0a1",
   "metadata": {},
   "source": [
    "> **Übung:** Warum ist das mehrfache Verwenden vom Testset zum Kontrollieren auch overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9359b007",
   "metadata": {},
   "source": [
    "Eine mögliche Lösung ist es, ein drittes Dataset einzuführen, das sogenannte **Validierungsset** (**Validationset**).\n",
    "\n",
    "Es soll verwendet werden, um während des Trainings schon ein Dataset zum Überprüfen der Performance zu haben, mit welchem das Modell **nicht** trainiert worden ist.\n",
    "\n",
    "Wir verwenden also für neuronale Netze oft 3 verschiedene Datasets:\n",
    "1) **Trainset:** Mit diesen Daten wird das Netzwerk trainiert.\n",
    "2) **Validationset:** Mit diesen Daten wird das Netzwerk während dem Trainingsvorgang immer wieder überprüft. Sollte sich die Performance für dieses Dataset nicht mehr ändern, so sollte man den Trainingsvorgang stoppen.\n",
    "3) **Testset:** Mit diesen Daten wird das Modell final getestet um nun zu sehen, wie gut es \"wirklich\" ist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5d70c6",
   "metadata": {},
   "source": [
    "Wir erstellen uns kurz eine Methode, die uns das Dataset generiert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087d9e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(path = os.path.join(\"..\", \"..\", \"_data\", \"housing.csv\")):\n",
    "    data = pd.read_csv(path, sep=',', header=0)\n",
    "\n",
    "    bin_colums = [\"mainroad\", \"guestroom\", \"basement\", \"hotwaterheating\", \"airconditioning\", \"prefarea\"]\n",
    "    for col in bin_colums:\n",
    "        data[col] = data[col].map({\"yes\":1,\"no\":0})\n",
    "\n",
    "    furnish_encoder = OrdinalEncoder(categories=[[\"unfurnished\",\"semi-furnished\",\"furnished\"]])\n",
    "\n",
    "    data[\"furnishingstatus\"] = furnish_encoder.fit_transform(data[[\"furnishingstatus\"]])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    scale_cols = [\"area\"]\n",
    "\n",
    "    data[scale_cols] = scaler.fit_transform(data[scale_cols])\n",
    "\n",
    "    data['price'] /= 1e6\n",
    "\n",
    "    X = data.drop(\"price\", axis=1)\n",
    "    y = data[\"price\"]\n",
    "\n",
    "    dataset = TensorDataset(torch.tensor(X.values, dtype=torch.float32), torch.tensor(y.values, dtype=torch.float32))\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976ff3e0",
   "metadata": {},
   "source": [
    "Erstellung eines Validation Sets in PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdc45f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset()\n",
    "\n",
    "train_set_ratio = 0.7\n",
    "test_set_ratio = 0.2\n",
    "validation_set_ratio = 0.1\n",
    "\n",
    "ratio_sum = train_set_ratio + test_set_ratio + validation_set_ratio\n",
    "\n",
    "assert np.isclose(ratio_sum, 1.0), f\"Ratios must sum to 1.0 but is {ratio_sum}\"\n",
    "\n",
    "train_length = int(round(train_set_ratio * len(dataset)))\n",
    "test_length = int(round(test_set_ratio * len(dataset)))\n",
    "validation_length = int(round(validation_set_ratio * len(dataset)))\n",
    "train_dataset, test_dataset, validation_dataset = random_split(dataset, [train_length, test_length, validation_length])\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16a2bc6",
   "metadata": {},
   "source": [
    "**Hinweis:** Die Verhältnisse 70/20/10 können natürlich auch angepasst werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5148ab1d",
   "metadata": {},
   "source": [
    "Diese können wir nun nutzen, um ein **Early Stopping** Verhalten zu implementieren."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd879b4",
   "metadata": {},
   "source": [
    "Mit **Early Stopping** meinen wir folgendes Vorgehen:\n",
    "* Wir trainieren unser Model auf den Trainings-Daten\n",
    "* Wir prüfen regelmäßig die aktuelle Performance des Modells am Validation Set\n",
    "* Sollte sich die Performance auf dem Validation Set über eine gewisse Zeit nicht verbessern, so stoppen wir mit dem Training\n",
    "* Es wird immer, wenn das Modell besser geworden ist, das aktuelle Modell gespeichert\n",
    "* Am Schluss wird das beste Modell geladen und wir Testen dieses beste Modell auf dem Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73e0261",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleRegressor().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc4dbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping parameters\n",
    "patience = 4\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "n_epochs = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844fab3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_mean_epoch = []\n",
    "validation_loss_mean_epoch = []\n",
    "\n",
    "model_export_path = os.path.join(\"..\", \"models\", \"best_model_nn_5.pth\")\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "    train_loss_epoch = np.mean(train_losses)\n",
    "    train_loss_mean_epoch.append(train_loss_epoch) # we save the mean train loss for each epoch to later have a list available if needed for e.g. plotting\n",
    "\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in validation_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            y_pred = model(X_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            val_losses.append(loss.item())\n",
    "    val_loss_epoch = np.mean(val_losses)\n",
    "    validation_loss_mean_epoch.append(val_loss_epoch) # we save the mean validation loss for each epoch to later have a list available if needed for e.g. plotting\n",
    "\n",
    "    print(f\"Epoch {epoch}/{n_epochs} — train_loss: {train_loss_epoch:.4f}, val_loss: {val_loss_epoch:.4f}\")\n",
    "\n",
    "    if val_loss_epoch < best_val_loss:\n",
    "        best_val_loss = val_loss_epoch\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), model_export_path)\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"No improvement for {epochs_no_improve} epochs.\")\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch} epochs. Best val loss: {best_val_loss:.4f}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905e937a",
   "metadata": {},
   "source": [
    "**Hinweis:** Wir haben hier schon einen Export vom Model mit `torch.save(model.state_dict(), model_export_path)` verwendet. Wir sehen uns das im nächsten Notebook genauer an!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cd85c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training, we load the best model and evaluate on the test set\n",
    "model_path = os.path.join(\"..\", \"models\", \"best_model_nn_5.pth\")\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "model.eval()\n",
    "test_losses = []\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        y_pred = model(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        test_losses.append(loss.item())\n",
    "avg_test_loss = np.mean(test_losses)\n",
    "print(f\"Test Loss of the best model: {avg_test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4aff102",
   "metadata": {},
   "source": [
    "Was genau passiert beim **Early Stopping**?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d1086a",
   "metadata": {},
   "source": [
    "![Overfitting_Underfitting_Loss_Curve](../resources/Overfitting_Underfitting_Loss_Curve.png)\n",
    "\n",
    "(von https://www.kaggle.com/code/ryanholbrook/overfitting-and-underfitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48c9e97",
   "metadata": {},
   "source": [
    "Wie oben im Bild dargestellt, wollen wir den Punkt erreichen, wo unser Validation-Loss minimal ist. Wir sehen aber, dass nach einer Zeit, der Validation Loss wieder nach **oben geht**, während der Trainingsloss immer weiter nach unten geht.\n",
    "\n",
    "Der Punkt, an dem der Validation Loss wieder nach oben geht, ist genau der Punkt, bei dem wir zu **overfitten** beginnen. Wir wollen also genau an diesem Punkt mit dem Training aufhören.\n",
    "\n",
    "Wie können wir das Erreichen?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a6fc05",
   "metadata": {},
   "source": [
    "* Wir berechnen den Validation Loss nach jeder Epoche\n",
    "* Ist er niedriger, als der bisherige beste Validation Loss, so speichern wir diesen als unseren neuen besten Loss und speichern auch das Modell ab.\n",
    "* Wird die Validation-Set Performance über eine gewisse Anzahl an Epochen (`patience`) nicht besser, so brechen wir mit dem Training ab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0400b2e0",
   "metadata": {},
   "source": [
    "**Hinweis:** Am Ende zählt trotzdem immer die Testset Performance. Im Normalfall ist aber der Validation Loss ein guter Indikator dafür."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503cdf09",
   "metadata": {},
   "source": [
    "> **Übung:** Ändere die `patience` so, dass wir tatsächlich einen besseren (ähnlichen) Test-Loss erzielen. *Tipp:* Probiere kleine Werte."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2991914",
   "metadata": {},
   "source": [
    "**Hinweis:** Um die Problematik, die in der vorigen Übung gezeigt wurde (zu oft \"Kontrollieren\" mit dem Validationset), zu beheben, wird oft das Validation Set nur alle $n$-Iterationen verwendet zum \"Kontrollieren\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee00aadb",
   "metadata": {},
   "source": [
    "### Lösung zu Problem 3 (Zu wenig Parameter des Trainingsvorgangs verfügbar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d33e757",
   "metadata": {},
   "source": [
    "Um den Trainingsvorgang besser überwachen zu können, ist es hilfreich, ein Tool wie zum Beispiel [WandB](https://docs.wandb.ai) zu verwenden. Es erlaubt uns, viele weitere Parameter des Trainings zu tracken und im Anschluss in einem Dashboard visuell darzustellen.\n",
    "\n",
    "Wir sehen uns nun an, wie wir das in unsere Trainingsmethode implementieren können."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d144fe17",
   "metadata": {},
   "source": [
    "Dazu installieren wir die `wandb` (ausgesprochen: Weights & Biases) mit `conda install wandb` bzw. `pip install wandb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc7e003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2447a8",
   "metadata": {},
   "source": [
    "Zuerst müssen wir uns einloggen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75a7b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301ec273",
   "metadata": {},
   "source": [
    "Nun müssen wir ein neues `wandb` Projekt initialisieren \n",
    "(siehe zur Anleitung ansonsten auch: [hier](https://docs.wandb.ai/models/tutorials/pytorch))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14a1847",
   "metadata": {},
   "source": [
    "**Hinweis:** Pro Initialisierung wird ein Run gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5abb7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"Regression_Network\", config={\n",
    "        \"learning_rate\": 1e-3,\n",
    "        \"batch_size\": 32,\n",
    "        \"patience\": 10,\n",
    "        \"n_epochs\": 300,\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"criterion\": \"MSELoss\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c00be10",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cd4e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset()\n",
    "\n",
    "train_set_ratio = 0.7\n",
    "test_set_ratio = 0.2\n",
    "validation_set_ratio = 0.1\n",
    "\n",
    "ratio_sum = train_set_ratio + test_set_ratio + validation_set_ratio\n",
    "\n",
    "assert np.isclose(ratio_sum, 1.0), f\"Ratios must sum to 1.0 but is {ratio_sum}\"\n",
    "\n",
    "train_length = int(round(train_set_ratio * len(dataset)))\n",
    "test_length = int(round(test_set_ratio * len(dataset)))\n",
    "validation_length = int(round(validation_set_ratio * len(dataset)))\n",
    "train_dataset, test_dataset, validation_dataset = random_split(dataset, [train_length, test_length, validation_length])\n",
    "\n",
    "batch_size = config.batch_size\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af93672",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleRegressor().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcf33a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.watch(model, criterion, log='all', log_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b390f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "model_export_path = os.path.join(\"..\", \"models\", \"best_model_nn_5.pth\")\n",
    "\n",
    "for epoch in range(1, config.n_epochs + 1):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "    train_loss_epoch = np.mean(train_losses)\n",
    "    train_loss_mean_epoch.append(train_loss_epoch)\n",
    "\n",
    "    ### NEW ###\n",
    "    metrics = {\n",
    "        \"train/loss\": train_loss_epoch,\n",
    "        \"train/epoch\": epoch\n",
    "    }\n",
    "    wandb.log(metrics)\n",
    "    ### END NEW ###\n",
    "\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in validation_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            y_pred = model(X_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            val_losses.append(loss.item())\n",
    "    val_loss_epoch = np.mean(val_losses)\n",
    "\n",
    "    ### NEW ###\n",
    "    val_metrics = {\n",
    "        \"val/loss\": val_loss_epoch,\n",
    "        \"val/epoch\": epoch\n",
    "    }\n",
    "    wandb.log(val_metrics)\n",
    "    ### END NEW ###\n",
    "\n",
    "    print(f\"Epoch {epoch}/{n_epochs} — train_loss: {train_loss_epoch:.4f}, val_loss: {val_loss_epoch:.4f}\")\n",
    "\n",
    "    if val_loss_epoch < best_val_loss:\n",
    "        best_val_loss = val_loss_epoch\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), model_export_path)\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"No improvement for {epochs_no_improve} epochs.\")\n",
    "        if epochs_no_improve >= config.patience:\n",
    "            print(f\"Early stopping triggered after {epoch} epochs. Best val loss: {best_val_loss:.4f}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e686c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training, we load the best model and evaluate on the test set\n",
    "model_path = os.path.join(\"..\", \"models\", \"best_model_nn_5.pth\")\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "model.eval()\n",
    "test_losses = []\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        y_pred = model(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        test_losses.append(loss.item())\n",
    "avg_test_loss = np.mean(test_losses)\n",
    "wandb.summary[\"test/loss\"] = avg_test_loss\n",
    "print(f\"Test Loss of the best model: {avg_test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8bca65",
   "metadata": {},
   "source": [
    "Nachdem wir mit `wandb` fertig sind, führen wir `wandb.finish()` aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d106b4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8816e1",
   "metadata": {},
   "source": [
    "Im Anschluss können wir nun auf der Homepage nachsehen, wie sich unsere (Model)Daten während dem Training verhalten haben. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5c1668",
   "metadata": {},
   "source": [
    "## Tipps und Tricks: Dropout und Batch-Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76bb7ed",
   "metadata": {},
   "source": [
    "Um unser Modell noch etwas besser zu machen, lernen wir jetzt noch eine weitere praktische Möglichkeit kennen, welche die Performance unseres Modells verbessern kann. Die Rede ist vom **Dropout**-Layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdb1f64",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02383fff",
   "metadata": {},
   "source": [
    "**Idee:**\n",
    "* Ein neuronales Netzwerk hat **viele Neuronen**, welche gemeinsam ein Muster erlernen.\n",
    "* Manche Neuronen sind dabei wichtiger als andere, sprich das Modell verlässt sich zu sehr auf einzelne Neuronen.\n",
    "* Dieses Verhalten neigt zu einer schlechten Generalisierung (i.e. overfitting).\n",
    "* Um dies zu verbessern, **schalten** wir **zufällig** einen Teil der **Neuronen** während des Trainings **aus**.\n",
    "* Dadurch muss das Modell lernen, alle Neuronen zu benutzen und nicht nur einen Teil."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41152fb6",
   "metadata": {},
   "source": [
    "![Dropout Visualization](../resources/Dropout_Visualized.png)\n",
    "\n",
    "(von https://medium.com/@amarbudhiraja/https-medium-com-amarbudhiraja-learning-less-to-learn-better-dropout-in-deep-machine-learning-74334da4bfc5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909116b9",
   "metadata": {},
   "source": [
    "Bei der **Evaluierung** wird diese Funktion ausgeschaltet und das Modell hat **alle Neuronen zur Verfügung**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad0b236",
   "metadata": {},
   "source": [
    "**Wichtig:** Für andere Architekturen (CNN's, Recurrent Neural Networks (zBsp. LSTM)) muss beim Dropout aufgepasst werden, ob es genau in dieser Form angewendet werden darf."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b1e98e",
   "metadata": {},
   "source": [
    "Wie können wir das in PyTorch verwenden?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527957f1",
   "metadata": {},
   "source": [
    "* Genauso wie `nn.Linear` gibt es auch `nn.Dropout(p)`\n",
    "* Dabei muss $p\\in[0,1]$ (genannt **Dropout-Rate**) als Parameter übergeben werden.\n",
    "* Es werden dann $(100\\cdot p)$\\% der Neuronen zufällig deaktiviert.\n",
    "* Wir können Dropout jedes Layer verwenden, sollten dabei (normalerweise) aber:\n",
    "    * es pro Layer immer nach der Aktivierungsfunktion einsetzten.\n",
    "    * nicht im allerletzten Layer einsetzen.\n",
    "    * kein zu hohes $p$ verwenden (zu großes $p$ führt zu underfitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409af618",
   "metadata": {},
   "source": [
    "**Vorteile:**\n",
    "\n",
    "* Kann gesehen werden, wie wenn wir mehrere verschiedene Modelle trainieren und dann den Durchschnitt nehmen. Dies verringert das Overfitting (Random Forest Idee)\n",
    "* Einfache Implementierung (wie ein weiteres Layer einfach in die Init-Funktion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9515c46",
   "metadata": {},
   "source": [
    "**Nachteile:**\n",
    "\n",
    "* Pro Trainingsschritt lernt nur ein Teil des Modells, somit sind normalerweise mehr Epochen also auch ein längeres Training notwendig.\n",
    "* Dropout-Rate ist ein weiterer Hyperparameter, der richtig gewählt werden muss.\n",
    "* Kann bei falscher Verwendung (insbesondere bei anderen Architekturen) schnell das Modell unbrauchbar machen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41516046",
   "metadata": {},
   "source": [
    "**Wichtig:** Nachdem Dropout nur beim Training angewendet werden soll, ist es extrem wichtig, dass wir beim Modell immer den Modus wechseln mit `model.train()` bzw. `model.eval()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a1bb1b",
   "metadata": {},
   "source": [
    "**Hinweis:** Es gibt auch noch weitere interessante Möglichkeiten, wie **BatchNormalization**, **LayerNormalization**, usw. Diese sehen wir uns nicht genauer an, können aber im Internet recherchiert werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8534945",
   "metadata": {},
   "source": [
    "Unser angepasstes Modell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2623169a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRegressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleRegressor, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(12, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df36618",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 300\n",
    "patience = 20\n",
    "model = SimpleRegressor().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5034b00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"price\", axis=1)\n",
    "y = data[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5bed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(torch.tensor(X.values, dtype=torch.float32), torch.tensor(y.values, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8597c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_ratio = 0.7\n",
    "test_set_ratio = 0.2\n",
    "validation_set_ratio = 0.1\n",
    "\n",
    "ratio_sum = train_set_ratio + test_set_ratio + validation_set_ratio\n",
    "\n",
    "assert np.isclose(ratio_sum, 1.0), f\"Ratios must sum to 1.0 but is {ratio_sum}\"\n",
    "\n",
    "train_length = int(round(train_set_ratio * len(dataset)))\n",
    "test_length = int(round(test_set_ratio * len(dataset)))\n",
    "validation_length = int(round(validation_set_ratio * len(dataset)))\n",
    "train_dataset, test_dataset, validation_dataset = random_split(dataset, [train_length, test_length, validation_length])\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b9db20",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "model_export_path = os.path.join(\"..\", \"models\", \"best_model_nn_5_advanced.pth\")\n",
    "\n",
    "train_loss_mean_epoch = []\n",
    "validation_loss_mean_epoch = []\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "    train_loss_epoch = np.mean(train_losses)\n",
    "    train_loss_mean_epoch.append(train_loss_epoch)\n",
    "\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in validation_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            y_pred = model(X_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            val_losses.append(loss.item())\n",
    "    val_loss_epoch = np.mean(val_losses)\n",
    "    validation_loss_mean_epoch.append(val_loss_epoch)\n",
    "\n",
    "    print(f\"Epoch {epoch}/{n_epochs} — train_loss: {train_loss_epoch:.4f}, val_loss: {val_loss_epoch:.4f}\")\n",
    "\n",
    "    if val_loss_epoch < best_val_loss:\n",
    "        best_val_loss = val_loss_epoch\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), model_export_path)\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"No improvement for {epochs_no_improve} epochs.\")\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch} epochs. Best val loss: {best_val_loss:.4f}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dd5c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training, we load the best model and evaluate on the test set\n",
    "export_model_path = os.path.join(\"..\", \"models\", \"best_model_nn_5_advanced.pth\")\n",
    "model.load_state_dict(torch.load(export_model_path))\n",
    "\n",
    "model.eval()\n",
    "test_losses = []\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        y_pred = model(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        test_losses.append(loss.item())\n",
    "avg_test_loss = np.mean(test_losses)\n",
    "print(f\"Test Loss of the best model: {avg_test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbd0fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_loss_mean_epoch, label='Training Loss')\n",
    "plt.plot(validation_loss_mean_epoch, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff70037b",
   "metadata": {},
   "source": [
    "### Skip-Connections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bf74bb",
   "metadata": {},
   "source": [
    "In vielen Netzwerken kann es vom Vorteil sein, sogenannte Skip-Connections zu verwenden. Sie sind ein Shortcut für das Netzwerk, sprich die Daten laufen sowohl durch das Netzwerk, als auch am Netzwerk vorbei und werden später wieder kombiniert. Dies hat sich in vielen Fällen als Vorteilhaft erwiesen und wird oft verwendet. Folgendes Bild zeigt eine beispielhafte Verwendung einer Skip-Connection über 2 Layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Skip_Connections](../resources/Skip_Connections.png)\n",
    "\n",
    "(von https://theaisummer.com/skip-connections/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec66da3f",
   "metadata": {},
   "source": [
    "**Mathematische Formulierung einer Skip-Connection:**\n",
    "\n",
    "Als Formel haben wir\n",
    "$$y = F(x)+x,$$\n",
    "\n",
    "dabei ist $x$ der Input des Layers $F$ repräsentiert die Funktion des Layers. $y$ ist der resultierende Output, welcher also eine Summe aus dem ursprünglichen Input und dem Output des Layers ist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c160267",
   "metadata": {},
   "source": [
    "**Vorteile:**\n",
    "\n",
    "* Netzwerk muss nur den Unterschied lernen.\n",
    "* Löst zu einem gewissen Grad das **Vanishing-Gradient** Problem, weil dann auch der Gradient diese Abkürzung hat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8896f8",
   "metadata": {},
   "source": [
    "**Nachteil(e):**\n",
    "\n",
    "* Die Dimensionen müssen zusammen passen, ansonsten können die beiden Outputs nicht zusammen addiert werden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2cb597",
   "metadata": {},
   "source": [
    "> **Übung:** Überlege dir Beispiele, wo Skip-Connections extrem Sinn machen können. Insbesondere, wenn du die eben genannten Nachteile betrachtest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86552d7a",
   "metadata": {},
   "source": [
    "**Hinweis:** Es gibt auch Ansätze, wo dann an den Verbindungsstellen (oben im Bild dargestellt als $\\oplus$) die Ergebnisse nicht addiert, sondern einfach Verkettet werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f9ac1c",
   "metadata": {},
   "source": [
    "**Beispielhafte Verwendung einer Skip-Connection in PyTorch:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f74a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRegressorwithSkipConnection(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleRegressorwithSkipConnection, self).__init__()\n",
    "        self.layer1 = nn.Linear(12, 24)\n",
    "        self.layer2 = nn.Linear(24, 12)\n",
    "        self.layer3 = nn.Linear(12, 6)\n",
    "        self.layer4 = nn.Linear(6, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        layer1_out = F.relu(self.layer1(x))\n",
    "        layer2_out = F.relu(self.layer2(layer1_out) + x)\n",
    "        layer3_out = F.relu(self.layer3(layer2_out))\n",
    "        output = self.layer4(layer3_out)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf4ddeb",
   "metadata": {},
   "source": [
    "**Hinweis:** Es können mehrere \"Skip-Verbindungen\" eingebaut werden, diese müssen dann einfach in der `forward()` Methode im Netzwerk richtig eingesetzt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c8cda4",
   "metadata": {},
   "source": [
    "### Tracken von Metriken im Trainingsprozess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb089cc0",
   "metadata": {},
   "source": [
    "Eine weitere praktische Sache ist, sich auch Metriken im Training anzeigen zu lassen. So können wir zum Beispiel nicht nur den Loss tracken, sondern auch zum Beispiel die **Accuracy**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9615db",
   "metadata": {},
   "source": [
    "Dabei müssen wir nur an jenen Stellen, wo der Loss berechnet wird, zusätzlich auch noch die Metrik berechnen und ausgeben. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017b5b5e",
   "metadata": {},
   "source": [
    "**Hinweis:** Es kann auch ein Early Stopping bzgl. einer Metrik implementiert werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7cec3d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd90e899",
   "metadata": {},
   "source": [
    "## Zusammenfassung Hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a96a87",
   "metadata": {},
   "source": [
    "* Batch Size\n",
    "* Modell Architektur (Layers, MLP, Aktivierungsfunktionen, Dropout usw.)\n",
    "* Learning Rate (Learning Rate Scheduler)\n",
    "* Optimizer (SGD, Adam, Adagrad)\n",
    "* Transformation von Daten\n",
    "* Early Stopping\n",
    "* Train/Test Split\n",
    "* Loss-Funktion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f65cb8",
   "metadata": {},
   "source": [
    "![Reel_First_Try_Suspicious](../resources/Instagram_Reel_First_Try_Suspicious.mp4)\n",
    "\n",
    "(von https://www.instagram.com/reel/DNiWMPWSjHc/?igsh=MW04OXNlczZjcHVydQ==)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
